## 📄 3. Transformer'lar Neler Yapabilir?

### Transformer'lar Her Yerde!

Transformer modelleri, doğal dil işleme (NLP), bilgisayarla görme, ses işleme ve daha birçok alanda çeşitli görevleri çözmek için kullanılır. Hugging Face ve Transformer modellerini kullanan ve topluluğa katkıda bulunan bazı şirketler ve kuruluşlar şunlardır:

![Hugging Face kullanan şirketler](https://huggingface.co/course/static/chapter1/transformers-companies.png)

Transformers kütüphanesi, bu paylaşılan modelleri oluşturma ve kullanma işlevselliğini sağlar. Model Hub, herkesin indirebileceği ve kullanabileceği milyonlarca önceden eğitilmiş model içerir. Ayrıca, kendi modellerinizi de Hub'a yükleyebilirsiniz!

⚠️ Hugging Face Hub, yalnızca Transformer modelleriyle sınırlı değildir. Herkes istediği türde modeli veya veri kümesini paylaşabilir! Tüm mevcut özelliklerden yararlanmak için bir huggingface.co hesabı oluşturun.

Transformer modellerinin nasıl çalıştığını derinlemesine incelemeden önce, bazı ilginç NLP problemlerini çözmek için nasıl kullanılabileceklerine dair birkaç örneğe bakalım.

---

## Pipelines ile Çalışmak

Transformers kütüphanesindeki en temel nesne `pipeline()` fonksiyonudur. Bu fonksiyon, bir modeli gerekli ön işleme ve son işleme adımlarıyla birleştirerek, herhangi bir metni doğrudan girdi olarak alıp anlaşılır bir yanıt almamızı sağlar:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python
[{'label': 'POSITIVE', 'score': 0.9598}]
```

Birden fazla cümle de verebiliriz!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python
[
    {'label': 'POSITIVE', 'score': 0.9598},
    {'label': 'NEGATIVE', 'score': 0.9994}
]
```

Varsayılan olarak, bu pipeline, İngilizce duygu analizi için ince ayar yapılmış belirli bir önceden eğitilmiş modeli seçer. `classifier` nesnesini oluşturduğunuzda model indirilir ve önbelleğe alınır. Komutu tekrar çalıştırırsanız, önbelleğe alınmış model kullanılır ve modeli tekrar indirmenize gerek kalmaz.

Bir metni bir pipeline'a verdiğinizde üç ana adım gerçekleşir:

1. Metin, modelin anlayabileceği bir formata dönüştürülür (ön işleme).
2. Ön işlenmiş girdiler modele aktarılır.
3. Modelin tahminleri, anlaşılır hale getirilmesi için son işleme tabi tutulur.

---

## Farklı Modlar İçin Mevcut Pipelines

`pipeline()` fonksiyonu, metin, görüntü, ses ve hatta çok modlu görevlerle çalışmanıza olanak tanıyan birden fazla modu destekler. Bu kursta metin görevlerine odaklanacağız, ancak transformer mimarisinin potansiyelini anlamak faydalıdır, bu yüzden kısaca özetleyelim.

İşte mevcut olanların bir özeti:

* **Metin Sınıflandırma**: Duygu analizi, konu sınıflandırması vb.
* **Adlandırılmış Varlık Tanıma (NER)**: Metindeki özel isimleri tanıma.
* **Soru-Cevap**: Bir bağlam verildiğinde sorulara yanıt verme.
* **Metin Oluşturma**: Belirli bir başlangıç metnine dayanarak yeni metinler üretme.
* **Özetleme**: Uzun metinleri kısa özetlere dönüştürme.
* **Çeviri**: Metni bir dilden başka bir dile çevirme.
* **Görüntü Sınıflandırma**: Görüntüleri belirli kategorilere ayırma.
* **Ses Tanıma**: Ses verilerini metne dönüştürme.

Bu pipelines, farklı görevler için önceden eğitilmiş modelleri ve ilgili ön/son işleme adımlarını içerir, bu da onları kullanmayı oldukça kolaylaştırır.

---
## Zero-shot Sınıflandırma

Şimdi, etiketlenmemiş metinleri sınıflandırmamız gereken daha zorlu bir görevi ele alalım.  
Bu, gerçek dünya projelerinde oldukça yaygın bir senaryodur çünkü metinleri etiketlemek hem zaman alıcıdır hem de alan bilgisi gerektirir.

Bu tür durumlar için `zero-shot-classification` pipeline'ı oldukça güçlüdür:  
Bu pipeline sayesinde sınıflandırma için hangi etiketlerin kullanılacağını kendimiz belirleyebiliriz —  
yani önceden eğitilmiş modelin varsayılan etiketlerine bağlı kalmak zorunda değiliz.

Örneğin, daha önce modeli bir cümleyi **olumlu (positive)** veya **olumsuz (negative)** olarak sınıflandırırken gördük —  
ama aslında model, istediğimiz **herhangi bir etiket setiyle** sınıflama yapabilir!

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```
```python
{
  'sequence': 'This is a course about the Transformers library',
  'labels': ['education', 'business', 'politics'],
  'scores': [0.84, 0.11, 0.04]
}

```
Bu pipeline'a "zero-shot" denmesinin nedeni:
Modeli kendi verin üzerinde ince ayar yapmana (fine-tune) gerek olmadan doğrudan kullanabilmen.
Yani istediğin etiket listesini verip, her biri için olasılık skoru alabilirsin!

## Metin Oluşturma (Text Generation)

Şimdi bir pipeline kullanarak nasıl metin oluşturabileceğimizi görelim.  
Buradaki temel fikir şudur: **bir başlangıç metni (prompt)** verirsiniz ve model, bu metni tamamlayacak şekilde geri kalanını oluşturur.

Bu, telefonlardaki **otomatik tamamlama özelliğine** oldukça benzer bir yaklaşımdır.

Not: Metin oluşturma süreci rastgelelik içerdiğinden, aşağıdaki çıktılarla birebir aynı sonucu almanız beklenmeyebilir — bu gayet normaldir.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python
[
  {'generated_text': 'In this course, we will teach you how to understand and use data flow and data interchange...'}
]

```
num_return_sequences ve max_length parametrelerini kullanarak:

Kaç adet farklı cümle oluşturulacağını
Cümlelerin uzunluğunu (maksimum kelime sayısını) kontrol edebilirsiniz.

```python
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)

```
## Model Hub'dan Herhangi Bir Modeli Pipeline'da Kullanmak

Önceki örneklerde her görev için **varsayılan model** kullanıldı.  
Ama Hugging Face Hub'dan istediğin **belirli bir modeli** seçerek de bir pipeline içinde kullanabilirsin.

Örneğin, metin oluşturma (text generation) görevinde özel bir model kullanmak istiyorsan:

1. Model Hub’a git ([https://huggingface.co/models](https://huggingface.co/models))  
2. Sol taraftan görev filtresi olarak `"text-generation"` seç  
3. Bu görevi destekleyen modeller listelenecek

Şimdi bu modeli birlikte deneyelim:  
**`HuggingFaceTB/SmolLM2-360M`**

Aşağıdaki şekilde, bu modeli doğrudan kullanabiliriz:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="HuggingFaceTB/SmolLM2-360M")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```
```python
[
  {'generated_text': 'In this course, we will teach you how to manipulate the world and ...'},
  {'generated_text': 'In this course, we will teach you how to become an expert and ...'}
]

```
Model Hub’da arama yaparken:

Sol menüden dil filtresi uygulayabilirsin

Örneğin Türkçe metin üretecek bir model bulabilirsin

Çok dilli (multilingual) modelleri de deneyebilirsin!

Seçtiğin modele tıkladığında genellikle bir deneme widget’ı da göreceksin.
Modeli indirip kodla çalıştırmadan önce doğrudan tarayıcıda test edebilirsin.
## Çıkarım Sağlayıcıları (Inference Providers)

Hugging Face modellerini, doğrudan tarayıcınızdan denemenizi sağlayan sistemlere **inference providers** denir.

Yani herhangi bir modelin sayfasına gidip bir metin yazarsanız, model bu girdiye göre anlık cevap üretir.  
Bu sayfa üzerinden modeli **çalıştırabilir**, çıktıyı anında görebilirsiniz — kod yazmadan!

![inference widget örneği](https://huggingface.co/course/static/chapter1/widget-example.png)

Bu çıkarım sağlayıcılarının çalıştığı altyapı, Hugging Face’in sunduğu bir servis olarak mevcuttur ve:

- Ücretsiz olarak herkesin kullanımına açık kısmı vardır  
- Daha yüksek ölçekli iş akışları için **ücretli sürümleri** de vardır

Eğer kurumsal düzeyde model çalıştırmak istiyorsan,  
[pricing](https://huggingface.co/pricing) sayfasına göz atabilirsin.

✏️ **Deneyin!**  
Hugging Face'de bir modele gidin ve inference widget üzerinden bir metin girin.  
Modelin cevabını gözlemleyin ve hangi görev için nasıl çalıştığını anlamaya çalışın.



## Sonuç

Transformer modelleri, çok çeşitli görevleri çözmek için güçlü araçlardır. Hugging Face'in Transformers kütüphanesi ve Model Hub'ı, bu modelleri kullanmayı ve paylaşmayı kolaylaştırır. `pipeline()` fonksiyonu, bu modellerle çalışmayı daha da basitleştirerek, karmaşık ön işleme ve son işleme adımlarını sizin için halleder.



