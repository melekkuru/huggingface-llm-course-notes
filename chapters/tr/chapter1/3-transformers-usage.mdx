## ğŸ“„ 3. Transformer'lar Neler Yapabilir?

### Transformer'lar Her Yerde!

Transformer modelleri, doÄŸal dil iÅŸleme (NLP), bilgisayarla gÃ¶rme, ses iÅŸleme ve daha birÃ§ok alanda Ã§eÅŸitli gÃ¶revleri Ã§Ã¶zmek iÃ§in kullanÄ±lÄ±r. Hugging Face ve Transformer modellerini kullanan ve topluluÄŸa katkÄ±da bulunan bazÄ± ÅŸirketler ve kuruluÅŸlar ÅŸunlardÄ±r:

![Hugging Face kullanan ÅŸirketler](https://huggingface.co/course/static/chapter1/transformers-companies.png)

Transformers kÃ¼tÃ¼phanesi, bu paylaÅŸÄ±lan modelleri oluÅŸturma ve kullanma iÅŸlevselliÄŸini saÄŸlar. Model Hub, herkesin indirebileceÄŸi ve kullanabileceÄŸi milyonlarca Ã¶nceden eÄŸitilmiÅŸ model iÃ§erir. AyrÄ±ca, kendi modellerinizi de Hub'a yÃ¼kleyebilirsiniz!

âš ï¸ Hugging Face Hub, yalnÄ±zca Transformer modelleriyle sÄ±nÄ±rlÄ± deÄŸildir. Herkes istediÄŸi tÃ¼rde modeli veya veri kÃ¼mesini paylaÅŸabilir! TÃ¼m mevcut Ã¶zelliklerden yararlanmak iÃ§in bir huggingface.co hesabÄ± oluÅŸturun.

Transformer modellerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± derinlemesine incelemeden Ã¶nce, bazÄ± ilginÃ§ NLP problemlerini Ã§Ã¶zmek iÃ§in nasÄ±l kullanÄ±labileceklerine dair birkaÃ§ Ã¶rneÄŸe bakalÄ±m.

---

## Pipelines ile Ã‡alÄ±ÅŸmak

Transformers kÃ¼tÃ¼phanesindeki en temel nesne `pipeline()` fonksiyonudur. Bu fonksiyon, bir modeli gerekli Ã¶n iÅŸleme ve son iÅŸleme adÄ±mlarÄ±yla birleÅŸtirerek, herhangi bir metni doÄŸrudan girdi olarak alÄ±p anlaÅŸÄ±lÄ±r bir yanÄ±t almamÄ±zÄ± saÄŸlar:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python
[{'label': 'POSITIVE', 'score': 0.9598}]
```

Birden fazla cÃ¼mle de verebiliriz!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python
[
    {'label': 'POSITIVE', 'score': 0.9598},
    {'label': 'NEGATIVE', 'score': 0.9994}
]
```

VarsayÄ±lan olarak, bu pipeline, Ä°ngilizce duygu analizi iÃ§in ince ayar yapÄ±lmÄ±ÅŸ belirli bir Ã¶nceden eÄŸitilmiÅŸ modeli seÃ§er. `classifier` nesnesini oluÅŸturduÄŸunuzda model indirilir ve Ã¶nbelleÄŸe alÄ±nÄ±r. Komutu tekrar Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, Ã¶nbelleÄŸe alÄ±nmÄ±ÅŸ model kullanÄ±lÄ±r ve modeli tekrar indirmenize gerek kalmaz.

Bir metni bir pipeline'a verdiÄŸinizde Ã¼Ã§ ana adÄ±m gerÃ§ekleÅŸir:

1. Metin, modelin anlayabileceÄŸi bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r (Ã¶n iÅŸleme).
2. Ã–n iÅŸlenmiÅŸ girdiler modele aktarÄ±lÄ±r.
3. Modelin tahminleri, anlaÅŸÄ±lÄ±r hale getirilmesi iÃ§in son iÅŸleme tabi tutulur.

---

## FarklÄ± Modlar Ä°Ã§in Mevcut Pipelines

`pipeline()` fonksiyonu, metin, gÃ¶rÃ¼ntÃ¼, ses ve hatta Ã§ok modlu gÃ¶revlerle Ã§alÄ±ÅŸmanÄ±za olanak tanÄ±yan birden fazla modu destekler. Bu kursta metin gÃ¶revlerine odaklanacaÄŸÄ±z, ancak transformer mimarisinin potansiyelini anlamak faydalÄ±dÄ±r, bu yÃ¼zden kÄ±saca Ã¶zetleyelim.

Ä°ÅŸte mevcut olanlarÄ±n bir Ã¶zeti:

* **Metin SÄ±nÄ±flandÄ±rma**: Duygu analizi, konu sÄ±nÄ±flandÄ±rmasÄ± vb.
* **AdlandÄ±rÄ±lmÄ±ÅŸ VarlÄ±k TanÄ±ma (NER)**: Metindeki Ã¶zel isimleri tanÄ±ma.
* **Soru-Cevap**: Bir baÄŸlam verildiÄŸinde sorulara yanÄ±t verme.
* **Metin OluÅŸturma**: Belirli bir baÅŸlangÄ±Ã§ metnine dayanarak yeni metinler Ã¼retme.
* **Ã–zetleme**: Uzun metinleri kÄ±sa Ã¶zetlere dÃ¶nÃ¼ÅŸtÃ¼rme.
* **Ã‡eviri**: Metni bir dilden baÅŸka bir dile Ã§evirme.
* **GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma**: GÃ¶rÃ¼ntÃ¼leri belirli kategorilere ayÄ±rma.
* **Ses TanÄ±ma**: Ses verilerini metne dÃ¶nÃ¼ÅŸtÃ¼rme.

Bu pipelines, farklÄ± gÃ¶revler iÃ§in Ã¶nceden eÄŸitilmiÅŸ modelleri ve ilgili Ã¶n/son iÅŸleme adÄ±mlarÄ±nÄ± iÃ§erir, bu da onlarÄ± kullanmayÄ± oldukÃ§a kolaylaÅŸtÄ±rÄ±r.

---
## Zero-shot SÄ±nÄ±flandÄ±rma

Åimdi, etiketlenmemiÅŸ metinleri sÄ±nÄ±flandÄ±rmamÄ±z gereken daha zorlu bir gÃ¶revi ele alalÄ±m.  
Bu, gerÃ§ek dÃ¼nya projelerinde oldukÃ§a yaygÄ±n bir senaryodur Ã§Ã¼nkÃ¼ metinleri etiketlemek hem zaman alÄ±cÄ±dÄ±r hem de alan bilgisi gerektirir.

Bu tÃ¼r durumlar iÃ§in `zero-shot-classification` pipeline'Ä± oldukÃ§a gÃ¼Ã§lÃ¼dÃ¼r:  
Bu pipeline sayesinde sÄ±nÄ±flandÄ±rma iÃ§in hangi etiketlerin kullanÄ±lacaÄŸÄ±nÄ± kendimiz belirleyebiliriz â€”  
yani Ã¶nceden eÄŸitilmiÅŸ modelin varsayÄ±lan etiketlerine baÄŸlÄ± kalmak zorunda deÄŸiliz.

Ã–rneÄŸin, daha Ã¶nce modeli bir cÃ¼mleyi **olumlu (positive)** veya **olumsuz (negative)** olarak sÄ±nÄ±flandÄ±rÄ±rken gÃ¶rdÃ¼k â€”  
ama aslÄ±nda model, istediÄŸimiz **herhangi bir etiket setiyle** sÄ±nÄ±flama yapabilir!

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```
```python
{
  'sequence': 'This is a course about the Transformers library',
  'labels': ['education', 'business', 'politics'],
  'scores': [0.84, 0.11, 0.04]
}

```
Bu pipeline'a "zero-shot" denmesinin nedeni:
Modeli kendi verin Ã¼zerinde ince ayar yapmana (fine-tune) gerek olmadan doÄŸrudan kullanabilmen.
Yani istediÄŸin etiket listesini verip, her biri iÃ§in olasÄ±lÄ±k skoru alabilirsin!

## Metin OluÅŸturma (Text Generation)

Åimdi bir pipeline kullanarak nasÄ±l metin oluÅŸturabileceÄŸimizi gÃ¶relim.  
Buradaki temel fikir ÅŸudur: **bir baÅŸlangÄ±Ã§ metni (prompt)** verirsiniz ve model, bu metni tamamlayacak ÅŸekilde geri kalanÄ±nÄ± oluÅŸturur.

Bu, telefonlardaki **otomatik tamamlama Ã¶zelliÄŸine** oldukÃ§a benzer bir yaklaÅŸÄ±mdÄ±r.

Not: Metin oluÅŸturma sÃ¼reci rastgelelik iÃ§erdiÄŸinden, aÅŸaÄŸÄ±daki Ã§Ä±ktÄ±larla birebir aynÄ± sonucu almanÄ±z beklenmeyebilir â€” bu gayet normaldir.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python
[
  {'generated_text': 'In this course, we will teach you how to understand and use data flow and data interchange...'}
]

```
num_return_sequences ve max_length parametrelerini kullanarak:

KaÃ§ adet farklÄ± cÃ¼mle oluÅŸturulacaÄŸÄ±nÄ±
CÃ¼mlelerin uzunluÄŸunu (maksimum kelime sayÄ±sÄ±nÄ±) kontrol edebilirsiniz.

```python
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)

```
## Model Hub'dan Herhangi Bir Modeli Pipeline'da Kullanmak

Ã–nceki Ã¶rneklerde her gÃ¶rev iÃ§in **varsayÄ±lan model** kullanÄ±ldÄ±.  
Ama Hugging Face Hub'dan istediÄŸin **belirli bir modeli** seÃ§erek de bir pipeline iÃ§inde kullanabilirsin.

Ã–rneÄŸin, metin oluÅŸturma (text generation) gÃ¶revinde Ã¶zel bir model kullanmak istiyorsan:

1. Model Hubâ€™a git ([https://huggingface.co/models](https://huggingface.co/models))  
2. Sol taraftan gÃ¶rev filtresi olarak `"text-generation"` seÃ§  
3. Bu gÃ¶revi destekleyen modeller listelenecek

Åimdi bu modeli birlikte deneyelim:  
**`HuggingFaceTB/SmolLM2-360M`**

AÅŸaÄŸÄ±daki ÅŸekilde, bu modeli doÄŸrudan kullanabiliriz:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="HuggingFaceTB/SmolLM2-360M")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```
```python
[
  {'generated_text': 'In this course, we will teach you how to manipulate the world and ...'},
  {'generated_text': 'In this course, we will teach you how to become an expert and ...'}
]

```
Model Hubâ€™da arama yaparken:

Sol menÃ¼den dil filtresi uygulayabilirsin

Ã–rneÄŸin TÃ¼rkÃ§e metin Ã¼retecek bir model bulabilirsin

Ã‡ok dilli (multilingual) modelleri de deneyebilirsin!

SeÃ§tiÄŸin modele tÄ±kladÄ±ÄŸÄ±nda genellikle bir deneme widgetâ€™Ä± da gÃ¶receksin.
Modeli indirip kodla Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce doÄŸrudan tarayÄ±cÄ±da test edebilirsin.
## Ã‡Ä±karÄ±m SaÄŸlayÄ±cÄ±larÄ± (Inference Providers)

Hugging Face modellerini, doÄŸrudan tarayÄ±cÄ±nÄ±zdan denemenizi saÄŸlayan sistemlere **inference providers** denir.

Yani herhangi bir modelin sayfasÄ±na gidip bir metin yazarsanÄ±z, model bu girdiye gÃ¶re anlÄ±k cevap Ã¼retir.  
Bu sayfa Ã¼zerinden modeli **Ã§alÄ±ÅŸtÄ±rabilir**, Ã§Ä±ktÄ±yÄ± anÄ±nda gÃ¶rebilirsiniz â€” kod yazmadan!

![inference widget Ã¶rneÄŸi](https://huggingface.co/course/static/chapter1/widget-example.png)

Bu Ã§Ä±karÄ±m saÄŸlayÄ±cÄ±larÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± altyapÄ±, Hugging Faceâ€™in sunduÄŸu bir servis olarak mevcuttur ve:

- Ãœcretsiz olarak herkesin kullanÄ±mÄ±na aÃ§Ä±k kÄ±smÄ± vardÄ±r  
- Daha yÃ¼ksek Ã¶lÃ§ekli iÅŸ akÄ±ÅŸlarÄ± iÃ§in **Ã¼cretli sÃ¼rÃ¼mleri** de vardÄ±r

EÄŸer kurumsal dÃ¼zeyde model Ã§alÄ±ÅŸtÄ±rmak istiyorsan,  
[pricing](https://huggingface.co/pricing) sayfasÄ±na gÃ¶z atabilirsin.

âœï¸ **Deneyin!**  
Hugging Face'de bir modele gidin ve inference widget Ã¼zerinden bir metin girin.  
Modelin cevabÄ±nÄ± gÃ¶zlemleyin ve hangi gÃ¶rev iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n.



## SonuÃ§

Transformer modelleri, Ã§ok Ã§eÅŸitli gÃ¶revleri Ã§Ã¶zmek iÃ§in gÃ¼Ã§lÃ¼ araÃ§lardÄ±r. Hugging Face'in Transformers kÃ¼tÃ¼phanesi ve Model Hub'Ä±, bu modelleri kullanmayÄ± ve paylaÅŸmayÄ± kolaylaÅŸtÄ±rÄ±r. `pipeline()` fonksiyonu, bu modellerle Ã§alÄ±ÅŸmayÄ± daha da basitleÅŸtirerek, karmaÅŸÄ±k Ã¶n iÅŸleme ve son iÅŸleme adÄ±mlarÄ±nÄ± sizin iÃ§in halleder.



