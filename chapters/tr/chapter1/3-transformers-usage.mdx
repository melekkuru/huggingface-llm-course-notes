## ğŸ“„ 3. Transformer'lar Neler Yapabilir?

### Transformer'lar Her Yerde!

Transformer modelleri, doÄŸal dil iÅŸleme (NLP), bilgisayarla gÃ¶rme, ses iÅŸleme ve daha birÃ§ok alanda Ã§eÅŸitli gÃ¶revleri Ã§Ã¶zmek iÃ§in kullanÄ±lÄ±r. Hugging Face ve Transformer modellerini kullanan ve topluluÄŸa katkÄ±da bulunan bazÄ± ÅŸirketler ve kuruluÅŸlar ÅŸunlardÄ±r:

![Hugging Face kullanan ÅŸirketler](https://huggingface.co/course/static/chapter1/transformers-companies.png)

Transformers kÃ¼tÃ¼phanesi, bu paylaÅŸÄ±lan modelleri oluÅŸturma ve kullanma iÅŸlevselliÄŸini saÄŸlar. Model Hub, herkesin indirebileceÄŸi ve kullanabileceÄŸi milyonlarca Ã¶nceden eÄŸitilmiÅŸ model iÃ§erir. AyrÄ±ca, kendi modellerinizi de Hub'a yÃ¼kleyebilirsiniz!

âš ï¸ Hugging Face Hub, yalnÄ±zca Transformer modelleriyle sÄ±nÄ±rlÄ± deÄŸildir. Herkes istediÄŸi tÃ¼rde modeli veya veri kÃ¼mesini paylaÅŸabilir! TÃ¼m mevcut Ã¶zelliklerden yararlanmak iÃ§in bir huggingface.co hesabÄ± oluÅŸturun.

Transformer modellerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± derinlemesine incelemeden Ã¶nce, bazÄ± ilginÃ§ NLP problemlerini Ã§Ã¶zmek iÃ§in nasÄ±l kullanÄ±labileceklerine dair birkaÃ§ Ã¶rneÄŸe bakalÄ±m.

---

## Pipelines ile Ã‡alÄ±ÅŸmak

Transformers kÃ¼tÃ¼phanesindeki en temel nesne `pipeline()` fonksiyonudur. Bu fonksiyon, bir modeli gerekli Ã¶n iÅŸleme ve son iÅŸleme adÄ±mlarÄ±yla birleÅŸtirerek, herhangi bir metni doÄŸrudan girdi olarak alÄ±p anlaÅŸÄ±lÄ±r bir yanÄ±t almamÄ±zÄ± saÄŸlar:

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python
[{'label': 'POSITIVE', 'score': 0.9598}]
```

Birden fazla cÃ¼mle de verebiliriz!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python
[
    {'label': 'POSITIVE', 'score': 0.9598},
    {'label': 'NEGATIVE', 'score': 0.9994}
]
```

VarsayÄ±lan olarak, bu pipeline, Ä°ngilizce duygu analizi iÃ§in ince ayar yapÄ±lmÄ±ÅŸ belirli bir Ã¶nceden eÄŸitilmiÅŸ modeli seÃ§er. `classifier` nesnesini oluÅŸturduÄŸunuzda model indirilir ve Ã¶nbelleÄŸe alÄ±nÄ±r. Komutu tekrar Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z, Ã¶nbelleÄŸe alÄ±nmÄ±ÅŸ model kullanÄ±lÄ±r ve modeli tekrar indirmenize gerek kalmaz.

Bir metni bir pipeline'a verdiÄŸinizde Ã¼Ã§ ana adÄ±m gerÃ§ekleÅŸir:

1. Metin, modelin anlayabileceÄŸi bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r (Ã¶n iÅŸleme).
2. Ã–n iÅŸlenmiÅŸ girdiler modele aktarÄ±lÄ±r.
3. Modelin tahminleri, anlaÅŸÄ±lÄ±r hale getirilmesi iÃ§in son iÅŸleme tabi tutulur.

---

## FarklÄ± Modlar Ä°Ã§in Mevcut Pipelines

`pipeline()` fonksiyonu, metin, gÃ¶rÃ¼ntÃ¼, ses ve hatta Ã§ok modlu gÃ¶revlerle Ã§alÄ±ÅŸmanÄ±za olanak tanÄ±yan birden fazla modu destekler. Bu kursta metin gÃ¶revlerine odaklanacaÄŸÄ±z, ancak transformer mimarisinin potansiyelini anlamak faydalÄ±dÄ±r, bu yÃ¼zden kÄ±saca Ã¶zetleyelim.

Ä°ÅŸte mevcut olanlarÄ±n bir Ã¶zeti:

* **Metin SÄ±nÄ±flandÄ±rma**: Duygu analizi, konu sÄ±nÄ±flandÄ±rmasÄ± vb.
* **AdlandÄ±rÄ±lmÄ±ÅŸ VarlÄ±k TanÄ±ma (NER)**: Metindeki Ã¶zel isimleri tanÄ±ma.
* **Soru-Cevap**: Bir baÄŸlam verildiÄŸinde sorulara yanÄ±t verme.
* **Metin OluÅŸturma**: Belirli bir baÅŸlangÄ±Ã§ metnine dayanarak yeni metinler Ã¼retme.
* **Ã–zetleme**: Uzun metinleri kÄ±sa Ã¶zetlere dÃ¶nÃ¼ÅŸtÃ¼rme.
* **Ã‡eviri**: Metni bir dilden baÅŸka bir dile Ã§evirme.
* **GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma**: GÃ¶rÃ¼ntÃ¼leri belirli kategorilere ayÄ±rma.
* **Ses TanÄ±ma**: Ses verilerini metne dÃ¶nÃ¼ÅŸtÃ¼rme.

Bu pipelines, farklÄ± gÃ¶revler iÃ§in Ã¶nceden eÄŸitilmiÅŸ modelleri ve ilgili Ã¶n/son iÅŸleme adÄ±mlarÄ±nÄ± iÃ§erir, bu da onlarÄ± kullanmayÄ± oldukÃ§a kolaylaÅŸtÄ±rÄ±r.

---
## Zero-shot SÄ±nÄ±flandÄ±rma

Åimdi, etiketlenmemiÅŸ metinleri sÄ±nÄ±flandÄ±rmamÄ±z gereken daha zorlu bir gÃ¶revi ele alalÄ±m.  
Bu, gerÃ§ek dÃ¼nya projelerinde oldukÃ§a yaygÄ±n bir senaryodur Ã§Ã¼nkÃ¼ metinleri etiketlemek hem zaman alÄ±cÄ±dÄ±r hem de alan bilgisi gerektirir.

Bu tÃ¼r durumlar iÃ§in `zero-shot-classification` pipeline'Ä± oldukÃ§a gÃ¼Ã§lÃ¼dÃ¼r:  
Bu pipeline sayesinde sÄ±nÄ±flandÄ±rma iÃ§in hangi etiketlerin kullanÄ±lacaÄŸÄ±nÄ± kendimiz belirleyebiliriz â€”  
yani Ã¶nceden eÄŸitilmiÅŸ modelin varsayÄ±lan etiketlerine baÄŸlÄ± kalmak zorunda deÄŸiliz.

Ã–rneÄŸin, daha Ã¶nce modeli bir cÃ¼mleyi **olumlu (positive)** veya **olumsuz (negative)** olarak sÄ±nÄ±flandÄ±rÄ±rken gÃ¶rdÃ¼k â€”  
ama aslÄ±nda model, istediÄŸimiz **herhangi bir etiket setiyle** sÄ±nÄ±flama yapabilir!

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```
```python
{
  'sequence': 'This is a course about the Transformers library',
  'labels': ['education', 'business', 'politics'],
  'scores': [0.84, 0.11, 0.04]
}

```
Bu pipeline'a "zero-shot" denmesinin nedeni:
Modeli kendi verin Ã¼zerinde ince ayar yapmana (fine-tune) gerek olmadan doÄŸrudan kullanabilmen.
Yani istediÄŸin etiket listesini verip, her biri iÃ§in olasÄ±lÄ±k skoru alabilirsin!

## Metin OluÅŸturma (Text Generation)

Åimdi bir pipeline kullanarak nasÄ±l metin oluÅŸturabileceÄŸimizi gÃ¶relim.  
Buradaki temel fikir ÅŸudur: **bir baÅŸlangÄ±Ã§ metni (prompt)** verirsiniz ve model, bu metni tamamlayacak ÅŸekilde geri kalanÄ±nÄ± oluÅŸturur.

Bu, telefonlardaki **otomatik tamamlama Ã¶zelliÄŸine** oldukÃ§a benzer bir yaklaÅŸÄ±mdÄ±r.

Not: Metin oluÅŸturma sÃ¼reci rastgelelik iÃ§erdiÄŸinden, aÅŸaÄŸÄ±daki Ã§Ä±ktÄ±larla birebir aynÄ± sonucu almanÄ±z beklenmeyebilir â€” bu gayet normaldir.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python
[
  {'generated_text': 'In this course, we will teach you how to understand and use data flow and data interchange...'}
]

```
num_return_sequences ve max_length parametrelerini kullanarak:

KaÃ§ adet farklÄ± cÃ¼mle oluÅŸturulacaÄŸÄ±nÄ±
CÃ¼mlelerin uzunluÄŸunu (maksimum kelime sayÄ±sÄ±nÄ±) kontrol edebilirsiniz.

```python
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)

```
## Model Hub'dan Herhangi Bir Modeli Pipeline'da Kullanmak

Ã–nceki Ã¶rneklerde her gÃ¶rev iÃ§in **varsayÄ±lan model** kullanÄ±ldÄ±.  
Ama Hugging Face Hub'dan istediÄŸin **belirli bir modeli** seÃ§erek de bir pipeline iÃ§inde kullanabilirsin.

Ã–rneÄŸin, metin oluÅŸturma (text generation) gÃ¶revinde Ã¶zel bir model kullanmak istiyorsan:

1. Model Hubâ€™a git ([https://huggingface.co/models](https://huggingface.co/models))  
2. Sol taraftan gÃ¶rev filtresi olarak `"text-generation"` seÃ§  
3. Bu gÃ¶revi destekleyen modeller listelenecek

Åimdi bu modeli birlikte deneyelim:  
**`HuggingFaceTB/SmolLM2-360M`**

AÅŸaÄŸÄ±daki ÅŸekilde, bu modeli doÄŸrudan kullanabiliriz:

```python
from transformers import pipeline

generator = pipeline("text-generation", model="HuggingFaceTB/SmolLM2-360M")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```
```python
[
  {'generated_text': 'In this course, we will teach you how to manipulate the world and ...'},
  {'generated_text': 'In this course, we will teach you how to become an expert and ...'}
]

```
Model Hubâ€™da arama yaparken:

Sol menÃ¼den dil filtresi uygulayabilirsin

Ã–rneÄŸin TÃ¼rkÃ§e metin Ã¼retecek bir model bulabilirsin

Ã‡ok dilli (multilingual) modelleri de deneyebilirsin!

SeÃ§tiÄŸin modele tÄ±kladÄ±ÄŸÄ±nda genellikle bir deneme widgetâ€™Ä± da gÃ¶receksin.
Modeli indirip kodla Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce doÄŸrudan tarayÄ±cÄ±da test edebilirsin.
## Ã‡Ä±karÄ±m SaÄŸlayÄ±cÄ±larÄ± (Inference Providers)

Hugging Face modellerini, doÄŸrudan tarayÄ±cÄ±nÄ±zdan denemenizi saÄŸlayan sistemlere **inference providers** denir.

Yani herhangi bir modelin sayfasÄ±na gidip bir metin yazarsanÄ±z, model bu girdiye gÃ¶re anlÄ±k cevap Ã¼retir.  
Bu sayfa Ã¼zerinden modeli **Ã§alÄ±ÅŸtÄ±rabilir**, Ã§Ä±ktÄ±yÄ± anÄ±nda gÃ¶rebilirsiniz â€” kod yazmadan!

![inference widget Ã¶rneÄŸi](https://huggingface.co/course/static/chapter1/widget-example.png)

Bu Ã§Ä±karÄ±m saÄŸlayÄ±cÄ±larÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± altyapÄ±, Hugging Faceâ€™in sunduÄŸu bir servis olarak mevcuttur ve:

- Ãœcretsiz olarak herkesin kullanÄ±mÄ±na aÃ§Ä±k kÄ±smÄ± vardÄ±r  
- Daha yÃ¼ksek Ã¶lÃ§ekli iÅŸ akÄ±ÅŸlarÄ± iÃ§in **Ã¼cretli sÃ¼rÃ¼mleri** de vardÄ±r

EÄŸer kurumsal dÃ¼zeyde model Ã§alÄ±ÅŸtÄ±rmak istiyorsan,  
[pricing](https://huggingface.co/pricing) sayfasÄ±na gÃ¶z atabilirsin.

âœï¸ **Deneyin!**  
Hugging Face'de bir modele gidin ve inference widget Ã¼zerinden bir metin girin.  
Modelin cevabÄ±nÄ± gÃ¶zlemleyin ve hangi gÃ¶rev iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n.

## BoÅŸluk Doldurma (Mask Filling)

`fill-mask` pipeline'Ä±, cÃ¼mledeki eksik kelimeyi tahmin etme gÃ¶revini yerine getirir.

Ã–rneÄŸin:

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)

```
```python
[
  {'sequence': 'This course will teach you all about mathematical models.',
   'score': 0.1961,
   'token': 30412,
   'token_str': ' mathematical'},
  {'sequence': 'This course will teach you all about computational models.',
   'score': 0.0405,
   'token': 38163,
   'token_str': ' computational'}
]
Burada <mask> yerine, modelin en olasÄ± gÃ¶rdÃ¼ÄŸÃ¼ kelimeler getirilir.
top_k=2 parametresi, en yÃ¼ksek olasÄ±lÄ±ÄŸa sahip 2 tahmini gÃ¶stermesini saÄŸlar.

Not: KullanÄ±lan <mask> kelimesi, modele Ã¶zgÃ¼ olabilir.
BazÄ± modeller farklÄ± mask token'larÄ± kullanÄ±r (Ã¶rneÄŸin [MASK]).
Bu nedenle baÅŸka bir modelle Ã§alÄ±ÅŸÄ±rken mask token'Ä±nÄ±n ne olduÄŸunu kontrol etmelisin.

Bunu modelin Hugging Face sayfasÄ±ndaki inference widgetâ€™Ä±nda gÃ¶rebilirsin.

âœï¸ Deneyin!
bert-base-cased modelini Hugging Face Model Hubâ€™da arayÄ±n.
Inference API widgetâ€™Ä±nda bu modelin mask tokenâ€™Ä±nÄ± bulun.
AynÄ± Ã¶rnek cÃ¼mlede nasÄ±l bir tahminde bulunduÄŸunu gÃ¶zlemleyin.

```
## AdlandÄ±rÄ±lmÄ±ÅŸ VarlÄ±k TanÄ±ma (Named Entity Recognition - NER)

`ner` pipeline'Ä±, metindeki kiÅŸi adlarÄ±, yer adlarÄ± ve organizasyonlar gibi Ã¶zel varlÄ±klarÄ± tanÄ±mak iÃ§in kullanÄ±lÄ±r.

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python
[
  {'entity_group': 'PER', 'score': 0.9981, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
  {'entity_group': 'ORG', 'score': 0.9796, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
  {'entity_group': 'LOC', 'score': 0.9932, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

Burada model doÄŸru ÅŸekilde tanÄ±mlamÄ±ÅŸtÄ±r:
- Sylvain â†’ kiÅŸi (PER)
- Hugging Face â†’ organizasyon (ORG)
- Brooklyn â†’ yer (LOC)

ğŸ’¡ `grouped_entities=True` sayesinde, aynÄ± varlÄ±ÄŸa ait kelimeler (Ã¶rneÄŸin "Hugging" ve "Face") birlikte gruplanÄ±r.

Ä°leride gÃ¶receÄŸimiz gibi bazÄ± kelimeler tokenizer aÅŸamasÄ±nda parÃ§alara bÃ¶lÃ¼nÃ¼r (Ã¶rneÄŸin "Sylvain" â†’ "S", "##yl", "##va", "##in").
Ama pipeline bu parÃ§alarÄ± post-processing adÄ±mÄ±nda doÄŸru ÅŸekilde birleÅŸtirir.

âœï¸ **Deneyin!**  
Model Hubâ€™da â€œpart-of-speech taggingâ€ (POS) yapabilen bir Ä°ngilizce model bulun.  
AynÄ± cÃ¼mlede bu modelin nasÄ±l etiketleme yaptÄ±ÄŸÄ±nÄ± inceleyin.

## Soru-Cevaplama (Question Answering)

Bu pipeline, belirli bir baÄŸlam (context) verildiÄŸinde **sorulara cevap verir.**
Model, cevabÄ± doÄŸrudan baÄŸlamdan **Ã§Ä±karÄ±m yoluyla** bulur â€” yani yeni bir metin Ã¼retmez.

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python
{'score': 0.6385, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

âœï¸ **Deneyin!**
FarklÄ± bir baÄŸlam ve soru yazarak deneyin. Modelin cevabÄ± doÄŸru ÅŸekilde Ã§Ä±kardÄ±ÄŸÄ±nÄ± kontrol edin.

---

## Ã–zetleme (Summarization)

Ã–zetleme (summarization), bir metni **daha kÄ±sa** bir biÃ§imde yeniden yazar, ancak **Ã¶nemli bilgileri korur.**

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science...
    """
)
```

```python
[{'summary_text': 'America has changed dramatically... the number of engineering graduates in the U.S. has declined...'}]
```

âœï¸ **Deneyin!**
Kendi uzun metninizi yazÄ±n ve modelin verdiÄŸi Ã¶zeti inceleyin. `max_length` veya `min_length` parametrelerini deÄŸiÅŸtirerek Ã¶zeti kontrol edin.

---

## Ã‡eviri (Translation)

Ã‡eviri gÃ¶revinde, varsayÄ±lan model kullanÄ±labileceÄŸi gibi **Model Hubâ€™dan bir Ã§eviri modeli** de seÃ§ilebilir.

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

âœï¸ **Deneyin!**
Model Hub'da farklÄ± diller iÃ§in Ã§eviri modelleri bulun ve aynÄ± cÃ¼mleyi birkaÃ§ farklÄ± dile Ã§evirtin.

---

## 10. GÃ¶rÃ¼ntÃ¼ ve Ses Pipelineâ€™larÄ± (Image and Audio Pipelines)

### GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma

```python
from transformers import pipeline

image_classifier = pipeline(
    task="image-classification", model="google/vit-base-patch16-224"
)
result = image_classifier(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
print(result)
```

```python
[
  {'label': 'lynx, catamount', 'score': 0.43},
  {'label': 'cougar, puma...', 'score': 0.03},
  ...
]
```

### Otomatik KonuÅŸma TanÄ±ma (ASR)

```python
from transformers import pipeline

transcriber = pipeline(
    task="automatic-speech-recognition", model="openai/whisper-large-v3"
)
result = transcriber(
    "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac"
)
print(result)
```

```python
{'text': 'I have a dream that one day this nation will rise up...'}
```

---

## Ã‡ok KaynaklÄ± Verileri BirleÅŸtirme

Transformer modelleri farklÄ± veri tÃ¼rlerinden gelen bilgileri **birleÅŸtirip iÅŸleyebilir.**

KullanÄ±m Ã¶rnekleri:
- Birden fazla veritabanÄ± veya kaynaktan arama yapmak
- Metin, gÃ¶rsel, ses gibi farklÄ± veri formatlarÄ±nÄ± birleÅŸtirmek
- DokÃ¼man ve metaverilerle bÃ¼tÃ¼ncÃ¼l yanÄ±t oluÅŸturmak

Bu tÃ¼r yetenekler, Ã§ok modlu (multimodal) sistemlerin temelidir.

---

## SonuÃ§ (Conclusion)

Bu bÃ¶lÃ¼mde gÃ¶sterilen pipelineâ€™lar **demonstrasyon amaÃ§lÄ±** hazÄ±rlanmÄ±ÅŸtÄ±r.
Her biri belirli gÃ¶revler iÃ§in programlanmÄ±ÅŸtÄ±r ve gÃ¶rev dÄ±ÅŸÄ±nda kullanÄ±lamazlar.

Bir sonraki bÃ¶lÃ¼mde `pipeline()` fonksiyonunun iÃ§ yapÄ±sÄ±nÄ± ve nasÄ±l Ã¶zelleÅŸtirilebileceÄŸini Ã¶ÄŸreneceÄŸiz âœ¨



